{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bay's Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_direct = '../training_data/train.pkl'\n",
    "test_direct = '../testing_data/test.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter as ctr\n",
    "from bs4 import BeautifulSoup\n",
    "import collections as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_pickle(train_direct)\n",
    "train = data.dropna(subset=['label'])\n",
    "train['text'] = train.msg.map(lambda x: x.get_text())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msgID</th>\n",
       "      <th>msg</th>\n",
       "      <th>time</th>\n",
       "      <th>authorID</th>\n",
       "      <th>label</th>\n",
       "      <th>fine_grained</th>\n",
       "      <th>rank</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>136322</td>\n",
       "      <td>&lt;p&gt;Me too Birdeye (it won't let me tag you &lt;im...</td>\n",
       "      <td>2015-05-05T07:13:48+00:00</td>\n",
       "      <td>292</td>\n",
       "      <td>green</td>\n",
       "      <td>allClear</td>\n",
       "      <td>Uber contributor</td>\n",
       "      <td>0</td>\n",
       "      <td>Me too Birdeye (it won't let me tag you ) exce...</td>\n",
       "      <td>[me, too, birdeye, (it, won't, let, me, tag, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>136323</td>\n",
       "      <td>&lt;p&gt;This thread is making me giddy with happine...</td>\n",
       "      <td>2015-05-05T07:30:00+00:00</td>\n",
       "      <td>292</td>\n",
       "      <td>green</td>\n",
       "      <td>allClear</td>\n",
       "      <td>Uber contributor</td>\n",
       "      <td>0</td>\n",
       "      <td>This thread is making me giddy with happiness ...</td>\n",
       "      <td>[this, thread, is, making, me, giddy, with, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>136327</td>\n",
       "      <td>&lt;p&gt;I found out my sister made herself an appoi...</td>\n",
       "      <td>2015-05-05T07:40:56+00:00</td>\n",
       "      <td>292</td>\n",
       "      <td>green</td>\n",
       "      <td>allClear</td>\n",
       "      <td>Uber contributor</td>\n",
       "      <td>0</td>\n",
       "      <td>I found out my sister made herself an appointm...</td>\n",
       "      <td>[i, found, out, my, sister, made, herself, an,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       msgID                                                msg  \\\n",
       "1703  136322  <p>Me too Birdeye (it won't let me tag you <im...   \n",
       "1704  136323  <p>This thread is making me giddy with happine...   \n",
       "1705  136327  <p>I found out my sister made herself an appoi...   \n",
       "\n",
       "                           time authorID  label fine_grained  \\\n",
       "1703  2015-05-05T07:13:48+00:00      292  green     allClear   \n",
       "1704  2015-05-05T07:30:00+00:00      292  green     allClear   \n",
       "1705  2015-05-05T07:40:56+00:00      292  green     allClear   \n",
       "\n",
       "                  rank affiliation  \\\n",
       "1703  Uber contributor           0   \n",
       "1704  Uber contributor           0   \n",
       "1705  Uber contributor           0   \n",
       "\n",
       "                                                   text  \\\n",
       "1703  Me too Birdeye (it won't let me tag you ) exce...   \n",
       "1704  This thread is making me giddy with happiness ...   \n",
       "1705  I found out my sister made herself an appointm...   \n",
       "\n",
       "                                                  clean  \n",
       "1703  [me, too, birdeye, (it, won't, let, me, tag, y...  \n",
       "1704  [this, thread, is, making, me, giddy, with, ha...  \n",
       "1705  [i, found, out, my, sister, made, herself, an,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Cleaning the text\n",
    "#\n",
    "train['clean'] = train.text.map(lambda x: x.lower().split())\n",
    "train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probablity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter as ctr\n",
    "\n",
    "t_counts = ctr(train.label)\n",
    "w_counts = ctr(w for row in train.clean for w in row)\n",
    "smooth=1e-10\n",
    "def Pt(T=''):\n",
    "    return t_counts[T]/len(data)\n",
    "\n",
    "def Pw(W=''):\n",
    "    if W not in w_counts:return smooth\n",
    "    return w_counts[W]/sum(w_counts.values())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditional propabilities\n",
    "w_t_counts={}\n",
    "\n",
    "for t in t_counts:\n",
    "    T_subframe = train[train.label==t]\n",
    "    w_t_counts[t] = ctr(w for row in T_subframe.clean for w in row)\n",
    "\n",
    "def Pwt(W='',T=''):\n",
    "    if W not in w_t_counts[T]:return smooth\n",
    "    return w_t_counts[T][W]/sum(w_t_counts[T].values())\n",
    "\n",
    "def Ptw(T='',W=''):\n",
    "    return Pwt(W,T)*Pt(T)/Pw(W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability for entire sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def Pts(T,S):\n",
    "    ''' Returns Probability of a T, type, given a S, sequence of words'''\n",
    "    return np.prod( [Ptw(T,w) for w in S] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "def P_types_s(S):\n",
    "    ''' Returns probability of types for a given S, sequence of words.'''\n",
    "    return [(t,Pts(t,S)) for t in t_counts]\n",
    "\n",
    "def best_t_s(S):\n",
    "    ''' Returns best predicted type for a given S, sequence of words.'''\n",
    "    return max(P_types_s(S), key=itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(test_direct)\n",
    "test = test.dropna(subset=['label'])\n",
    "test['text'] = test.msg.map(lambda x: x.get_text())\n",
    "test['clean'] = test.text.map(lambda x: x.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msgID</th>\n",
       "      <th>msg</th>\n",
       "      <th>authorID</th>\n",
       "      <th>label</th>\n",
       "      <th>fine_grained</th>\n",
       "      <th>rank</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>text</th>\n",
       "      <th>clean</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>194795</td>\n",
       "      <td>Hey I've done that!! They have people who come...</td>\n",
       "      <td>5111</td>\n",
       "      <td>green</td>\n",
       "      <td>allClear</td>\n",
       "      <td>Builder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey I've done that!! They have people who come...</td>\n",
       "      <td>[hey, i've, done, that!!, they, have, people, ...</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7806</th>\n",
       "      <td>194911</td>\n",
       "      <td>It is a separate issue yes but they just hate ...</td>\n",
       "      <td>5111</td>\n",
       "      <td>amber</td>\n",
       "      <td>followupOk</td>\n",
       "      <td>Builder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It is a separate issue yes but they just hate ...</td>\n",
       "      <td>[it, is, a, separate, issue, yes, but, they, j...</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td>194938</td>\n",
       "      <td>I'm really sorry but I don't want to call them...</td>\n",
       "      <td>5111</td>\n",
       "      <td>red</td>\n",
       "      <td>currentAcuteDistress</td>\n",
       "      <td>Builder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm really sorry but I don't want to call them...</td>\n",
       "      <td>[i'm, really, sorry, but, i, don't, want, to, ...</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       msgID                                                msg authorID  \\\n",
       "7782  194795  Hey I've done that!! They have people who come...     5111   \n",
       "7806  194911  It is a separate issue yes but they just hate ...     5111   \n",
       "7815  194938  I'm really sorry but I don't want to call them...     5111   \n",
       "\n",
       "      label          fine_grained     rank affiliation  \\\n",
       "7782  green              allClear  Builder         NaN   \n",
       "7806  amber            followupOk  Builder         NaN   \n",
       "7815    red  currentAcuteDistress  Builder         NaN   \n",
       "\n",
       "                                                   text  \\\n",
       "7782  Hey I've done that!! They have people who come...   \n",
       "7806  It is a separate issue yes but they just hate ...   \n",
       "7815  I'm really sorry but I don't want to call them...   \n",
       "\n",
       "                                                  clean predict  \n",
       "7782  [hey, i've, done, that!!, they, have, people, ...   green  \n",
       "7806  [it, is, a, separate, issue, yes, but, they, j...   green  \n",
       "7815  [i'm, really, sorry, but, i, don't, want, to, ...   green  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['predict'] = test.clean.map(best_t_s)\n",
    "test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common baseline:  0.54\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Most common baseline\n",
    "#\n",
    "print(\"Most common baseline: \",max(c.Counter(test['label']).values())/(len(test['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bay's results:  0.5325\n"
     ]
    }
   ],
   "source": [
    "results = test.predict==test.label\n",
    "print(\"Naive Bay's results: \",sum(results)/len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying based on ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probablity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_counts = ctr(train['rank'])\n",
    "#conditional propabilities\n",
    "r_t_counts={}\n",
    "\n",
    "def Pr(R=''):\n",
    "    if R not in r_counts:return smooth\n",
    "    return r_counts[R]/sum(r_counts.values())    \n",
    "\n",
    "r_t_counts={}\n",
    "for t in t_counts:\n",
    "    T_subframe = train[train.label==t]\n",
    "    r_t_counts[t] = ctr(T_subframe['rank'])\n",
    "\n",
    "def Prt(R='',T=''):\n",
    "    if R not in r_t_counts[T]:return smooth\n",
    "    return r_t_counts[T][R]/sum(r_t_counts[T].values())\n",
    "\n",
    "def Ptr(T='',R=''):\n",
    "    return Prt(R,T)*Pt(T)/Pr(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability for entire sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('green', 0.010872871046228711),\n",
       " ('amber', 0.004501216545012165),\n",
       " ('red', 0.0020833333333333333),\n",
       " ('crisis', 0.0006082725060827251)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def P_types_r(r):\n",
    "    ''' Returns probability of types for a given rank.'''\n",
    "    return [(t,Ptr(t,r)) for t in t_counts]\n",
    "def best_t_r(r):\n",
    "    ''' Returns best predicted type for a given rank.'''\n",
    "    return max(P_types_r(r), key=itemgetter(1))[0]\n",
    "P_types_r('Builder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying based on ranks:  0.545\n"
     ]
    }
   ],
   "source": [
    "test['predict_rank'] = test['rank'].map(best_t_r)\n",
    "results = test.predict_rank==test.label\n",
    "print(\"Classifying based on ranks: \",sum(results)/len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining rank and NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Casual scribe',\n",
       " 'Frequent Visitor',\n",
       " 'Frequent scribe',\n",
       " 'Mod',\n",
       " 'Mod Squad',\n",
       " 'Post Mod',\n",
       " 'Rookie',\n",
       " 'Rookie scribe',\n",
       " 'Special Guest Contributor',\n",
       " 'Star contributor',\n",
       " 'Super frequent scribe',\n",
       " 'Uber contributor',\n",
       " 'Visitor',\n",
       " 'Youth Ambassador'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_1 = set(train['rank'])\n",
    "list_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Builder',\n",
       " 'Casual scribe',\n",
       " 'Frequent scribe',\n",
       " 'Mod',\n",
       " 'Rookie',\n",
       " 'Rookie scribe',\n",
       " 'Star contributor',\n",
       " 'Super frequent scribe',\n",
       " 'Super star contributor',\n",
       " 'Uber contributor',\n",
       " 'Visitor'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Issue: The ranks in the data sets are not the same!\n",
    "list_2 = set(test['rank'])\n",
    "list_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_predict =[]\n",
    "for i in range(len(test)):\n",
    "    x1 = P_types_r(test['rank'].iloc[i])\n",
    "    x2 = P_types_s(test['clean'].iloc[i])\n",
    "    keys,v1=zip(*x1)\n",
    "    keys,v2=zip(*x2)\n",
    "    combined_predict.append(max(list(zip(keys,np.multiply(v1,v2))), key=itemgetter(1))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = combined_predict==test.label\n",
    "sum(results)/len(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
